{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanmullan/Code/.virtualenvs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from timeit import default_timer as tic\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antifix(x):\n",
    "    \"\"\"Similar to numpy's fix function, but rounds away from 0\"\"\"\n",
    "    return (np.sign(x) * np.ceil(np.absolute(x))).astype(int)\n",
    "    \n",
    "\n",
    "def shift(count=None):\n",
    "    \"\"\"Get an array of ints from a normal distribution centered around 0 with a stddev of 1\n",
    "    --returns a single int rather than an array if count is None\n",
    "    \"\"\"\n",
    "    return constrain(antifix(np.random.normal(size=count)), -3, 3)\n",
    "\n",
    "def either(p=None):\n",
    "    \"\"\"Shortcut for a boolean choice with probabilities\"\"\"\n",
    "    return np.random.choice(2, p=p)\n",
    "\n",
    "def constrain(x, low, high, decimals=2):\n",
    "    \"\"\"Constrains the value to the given range (inclusive) and rounds to number of decimals\"\"\"\n",
    "    value = None\n",
    "    if x < low:\n",
    "        value = low\n",
    "    elif x > high:\n",
    "        value = high\n",
    "    else:\n",
    "        value = x\n",
    "    return np.around(value, decimals)\n",
    "    \n",
    "def distrib(x):\n",
    "    \"\"\"Softmax, but doubles values to increase disparity\"\"\"\n",
    "    x_exp = np.exp(np.array(x) * 2)\n",
    "    return x_exp / x_exp.sum()\n",
    "\n",
    "def init_drop(p=None):\n",
    "    \"\"\"Return a random initial dropout\"\"\"\n",
    "    return np.around(np.random.uniform(0, 0.5), 2)\n",
    "\n",
    "acts = ['Linear','Tanh','ReLU','LeakyReLU','Sigmoid']\n",
    "activations = [None, tf.nn.tanh, tf.nn.relu, tf.nn.leaky_relu, tf.nn.sigmoid]\n",
    "def init_act(p=None):\n",
    "    \"\"\"Return a random initial activation function\"\"\"\n",
    "    return np.random.choice(np.arange(len(activations)), p=p)\n",
    "    \n",
    "def init_hsize():\n",
    "    \"\"\"Return a random initial fully-connected layer size\n",
    "    values are [4,10] since hidden size will be 2^x for whatever x is returned\"\"\"\n",
    "    return np.random.randint(4,10 + 1)\n",
    "\n",
    "def init_kernel():\n",
    "    return np.random.randint(1, 11)\n",
    "\n",
    "def init_stride():\n",
    "    return np.random.randint(1, 5)\n",
    "\n",
    "def init_lr():\n",
    "    return constrain(np.random.exponential(scale=0.09), 0.001, 0.2, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"V2.0 - Tree-like structure, but no branching yet\"\"\"\n",
    "class Node(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.child = None  # will only be 1 child for this version\n",
    "\n",
    "    def __iadd__(self, node):\n",
    "        if self.child:\n",
    "            self.child += node\n",
    "        else:\n",
    "            self.child = node\n",
    "        return self\n",
    "    \n",
    "    def get(self, depth):\n",
    "        if self.child is None:\n",
    "            return None\n",
    "        if depth==0:\n",
    "            return self.child\n",
    "        else:\n",
    "            return self.child.get(depth-1)\n",
    "        \n",
    "    def trim(self, depth):\n",
    "        if depth==0:\n",
    "            self.child = None\n",
    "        else:\n",
    "            self.child.trim(depth-1)\n",
    "        \n",
    "class DenseNode(Node):\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        Node.__init__(self)\n",
    "        \n",
    "        if config:\n",
    "            self.dropout = config[0]\n",
    "            self.activation_func = config[1]\n",
    "            self.size = config[2]\n",
    "        else:\n",
    "            self.dropout = init_drop()\n",
    "            self.activation_func = init_act()\n",
    "            self.size = init_hsize()\n",
    "        \n",
    "        self.type = \"Dense\"\n",
    "            \n",
    "    def show(self):\n",
    "        print(\"\\t{}\\tSize: {}\\tActivation: {}\\tDropout: {}\".format(self.type, 2**self.size, acts[self.activation_func], self.dropout))\n",
    "        if(self.child):\n",
    "            self.child.show()\n",
    "            \n",
    "    def __call__(self, x, mode):\n",
    "        dense = tf.layers.dense(inputs=x, units=2**self.size, activation=activations[self.activation_func])\n",
    "        if self.dropout != 0:\n",
    "                dense = tf.layers.dropout(inputs=dense, rate=self.dropout, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        if self.child:\n",
    "            return self.child(dense, mode)\n",
    "        return dense\n",
    "    \n",
    "    def mutate(self, mutation_rate):\n",
    "        if np.random.rand() < mutation_rate:\n",
    "            self.size = constrain(self.size + shift(), 4, 10)\n",
    "            \n",
    "        if np.random.rand() < mutation_rate:\n",
    "            self.dropout = constrain(self.dropout + np.random.normal(scale=0.05), 0, 0.5)\n",
    "            \n",
    "        if np.random.rand() < mutation_rate:\n",
    "            self.activation_func = init_act()\n",
    "            \n",
    "        if self.child:\n",
    "            self.child.mutate(mutation_rate)\n",
    "            \n",
    "    def crossover(self, other, p):\n",
    "        config = [self.dropout, self.activation_func, self.size]\n",
    "        if either(p):\n",
    "            config[0] = other.dropout\n",
    "        if either(p):\n",
    "            config[1] = other.activation_func\n",
    "        if either(p):\n",
    "            config[2] = other.size\n",
    "        return config\n",
    "    \n",
    "    def config(self):\n",
    "        return [self.dropout, self.activation_func, self.size]\n",
    "    \n",
    "class ConvNode(Node):\n",
    "    def __init__(self, config=None):\n",
    "        Node.__init__(self)\n",
    "        if config:\n",
    "            self.dropout = config[0]\n",
    "            self.activation_func = config[1]\n",
    "            self.filters = config[2]\n",
    "            self.kernel_size = config[3]\n",
    "            self.strides = config[4]\n",
    "        else:\n",
    "            self.dropout = init_drop()\n",
    "            self.activation_func = init_act()\n",
    "            self.filters = init_hsize()\n",
    "            self.kernel_size = init_kernel()\n",
    "            self.strides = init_stride()\n",
    "        self.padding = \"same\"\n",
    "        self.type = \"Conv2D\"\n",
    "        \n",
    "    def show(self):\n",
    "        acts = ['Linear','Tanh','ReLU','LeakyReLU','Sigmoid']\n",
    "        print(\"\\t{}\\tFilers: {}\\tKernel/Stride: {}/{}\\tActivation: {}\\tDropout: {}\".format(self.type, 2**self.filters, self.kernel_size, self.strides, acts[self.activation_func], self.dropout))\n",
    "        if(self.child):\n",
    "            self.child.show()\n",
    "            \n",
    "    def __call__(self, x, mode):\n",
    "        conv = tf.layers.conv2d(inputs=x, filters=2**self.filters, kernel_size=(self.kernel_size, self.kernel_size), strides=(self.strides, self.strides), activation=activations[self.activation_func])\n",
    "        if self.dropout != 0:\n",
    "            conv = tf.layers.dropout(inputs=conv, rate=self.dropout, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        if self.child:\n",
    "            if self.child.type == 'Dense':\n",
    "                conv = tf.layers.flatten(conv)\n",
    "            return self.child(conv, mode)\n",
    "        return tf.layers.flatten(conv)\n",
    "    \n",
    "    def mutate(self, mutation_rate):\n",
    "        if np.random.rand() < mutation_rate:\n",
    "            self.filters = constrain(self.filters +shift(), 4, 10)\n",
    "        if np.random.rand() < mutation_rate:\n",
    "            self.kernel_size = constrain(self.kernel_size + shift(), 1, 10)\n",
    "        if np.random.rand() < mutation_rate:\n",
    "            self.strides = constrain(self.strides + shift(), 1, 4)\n",
    "        if np.random.rand() < mutation_rate:\n",
    "            self.dropout = constrain(self.dropout + np.random.normal(scale=0.05), 0, 0.5)\n",
    "        if np.random.rand() < mutation_rate:\n",
    "            self.activation_func = init_act()\n",
    "        if self.child:\n",
    "            self.child.mutate(mutation_rate)\n",
    "            \n",
    "    def crossover(self, other, p):\n",
    "        config = [self.dropout, self.activation_func, self.filters, self.kernel_size, self.strides]\n",
    "        if either(p):\n",
    "            config[0] = other.dropout\n",
    "        if either(p):\n",
    "            config[1] = other.activation_func\n",
    "        if either(p):\n",
    "            config[2] = other.filters\n",
    "        if either(p):\n",
    "            config[3] = other.kernel_size\n",
    "        if either(p):\n",
    "            config[4] = other.strides\n",
    "        return config\n",
    "    \n",
    "    def config(self):\n",
    "        return [self.dropout, self.activation_func, self.filters, self.kernel_size, self.strides]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    \"\"\"Acts as the root as well\"\"\"\n",
    "    def __init__(self, name, mutation_rate=0.1, grow_prob=0.1, shrink_prob=0.1, num_nodes=0, load=False):\n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "        self.child = None  # will only be 1 child for now\n",
    "        self.name = name\n",
    "        \n",
    "        self.size = 0\n",
    "        self.fitness = 0\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.grow_prob = grow_prob\n",
    "        self.shrink_prob = shrink_prob\n",
    "        self.age = 0  # Total number of epochs seen\n",
    "        self.accuracy = -1\n",
    "        self.loss = -1\n",
    "        self.train_time = -1\n",
    "        \n",
    "        self.learning_rate = init_lr()#0.001\n",
    "\n",
    "        for i in range(num_nodes):\n",
    "            if either():\n",
    "                self.add_end(DenseNode())\n",
    "            else:\n",
    "                self.add_front(ConvNode())\n",
    "            \n",
    "        if load:\n",
    "            self.classifier = tf.estimator.Estimator(\n",
    "                model_fn=self.model_fn,\n",
    "                model_dir=\"./\"+self.name\n",
    "            )\n",
    "        else:\n",
    "            self.classifier = tf.estimator.Estimator(\n",
    "                model_fn=self.model_fn\n",
    "            )\n",
    "            \n",
    "    def show(self):\n",
    "        print(\"---------------------------------------------\")\n",
    "        print(self.name+\"\\tlr:{}\".format(self.learning_rate))\n",
    "        if(self.fitness!=0):\n",
    "            print(\"\\tFitness: {}\\tAccuracy: {}\\tLoss: {}\".format(self.fitness, self.accuracy, self.loss))\n",
    "        self.child.show()\n",
    "        print(\"---------------------------------------------\")\n",
    "\n",
    "    def update_fitness(self):\n",
    "        self.fitness = self.accuracy\n",
    "    \n",
    "    def name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def train(self, input_fn, verbose=False, steps=20000):\n",
    "        try:\n",
    "            logging_hooks = None\n",
    "            if verbose:\n",
    "                logged_vars = {\"probabilities\": \"softmax_tensor\"}\n",
    "                logging_hooks = [tf.train.LoggingTensorHook(tensors=logged_vars, every_n_iter=2000)]\n",
    "\n",
    "            start = tic()\n",
    "            self.classifier.train(\n",
    "                input_fn=input_fn,\n",
    "                steps=steps,\n",
    "                hooks=logging_hooks\n",
    "            )\n",
    "            self.train_time = tic()-start\n",
    "            if self.train_time > 45:\n",
    "                self.fitness = -10\n",
    "            self.age += steps\n",
    "            print(\"Time to train model \\\"{}\\\": {:.4f}\".format(self.name, self.train_time))\n",
    "        except:\n",
    "            print(\"TensorFlow failure --\")\n",
    "            self.show()\n",
    "            self.fitness = -10\n",
    "#             raise ValueError()\n",
    "        \n",
    "    def test(self, input_fn):\n",
    "        results = self.classifier.evaluate(input_fn)\n",
    "        self.accuracy = results['accuracy']\n",
    "        self.age = results['global_step']\n",
    "        self.loss = results['loss']\n",
    "        self.update_fitness()\n",
    "        return results\n",
    "        \n",
    "    def model_fn(self, features, labels, mode):\n",
    "        input_layer = tf.reshape(features[\"x\"], [-1, 784])\n",
    "        \n",
    "        if self.child.type == \"Conv2D\":\n",
    "            input_layer = tf.reshape(input_layer, [-1, 28,28,1])\n",
    "        \n",
    "        \n",
    "        hidden = self.child(input_layer, mode)\n",
    "        \n",
    "        logits = tf.layers.dense(inputs=hidden, units=10)\n",
    "        \n",
    "        predictions = {\n",
    "            \"classes\": tf.argmax(input=logits, axis=1),\n",
    "            \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        }\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "        \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate)\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step()\n",
    "            )\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "        \n",
    "        eval_metric_ops = {\n",
    "            \"accuracy\":tf.metrics.accuracy(\n",
    "                labels=labels,\n",
    "                predictions=predictions['classes']\n",
    "            )\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metric_ops\n",
    "        )\n",
    "        \n",
    "    def __call__(self):\n",
    "        result = self.children[0](self.x)\n",
    "        logits = tf.layers.dense(inputs=result, units=10, name=\"logits\")\n",
    "        \n",
    "        classes = tf.argmax(input=logits, axis=1)\n",
    "        probs = tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        \n",
    "    def add_end(self, node):  # +=\n",
    "        self.size += 1\n",
    "        if self.child is not None:\n",
    "            self.child += node\n",
    "        else:\n",
    "            self.child = node\n",
    "    \n",
    "    def add_front(self, node):\n",
    "        self.size += 1\n",
    "        if self.child is not None:\n",
    "            node.child = self.child\n",
    "            self.child = node.child\n",
    "        else:\n",
    "            self.child = node\n",
    "    \n",
    "    def get_mode(self):\n",
    "        return self.mode\n",
    "    \n",
    "    def __getitem__(self, depth):\n",
    "        if self.child is None:\n",
    "            raise IndexError(\"There is no layer at depth {}.\".format(depth))\n",
    "        if depth==0:\n",
    "            return self.child\n",
    "        else:\n",
    "            result = self.child.get(depth-1)\n",
    "            if result is None:\n",
    "                self.show()\n",
    "                raise IndexError(\"There is no layer at depth {}.\".format(depth))\n",
    "            return result\n",
    "        \n",
    "    def mutate(self, p=None):\n",
    "        if p is None:\n",
    "            p = self.mutation_rate\n",
    "        if np.random.rand() < p:\n",
    "            self.learning_rate = constrain(np.exp(np.log(self.learning_rate) + shift()), 0.0001, 0.2, decimals=4)\n",
    "        if either(np.array([1-self.shrink_prob, self.shrink_prob])) and self.size > 1:\n",
    "            self.size -= 1\n",
    "            if either():\n",
    "                self.child.trim(self.size)\n",
    "            else:\n",
    "                self.child = self.child.child\n",
    "        if either(np.array([1-self.grow_prob, self.grow_prob])):\n",
    "            if either():\n",
    "                self.add_end(DenseNode())\n",
    "            else:\n",
    "                self.add_front(ConvNode())\n",
    "        if self.child:\n",
    "            self.child.mutate(p)\n",
    "            \n",
    "    def crossover(self, other, name, mode='even'):\n",
    "        \"\"\"Crossover to get offspring of two trees\n",
    "        mode -- either even or biased. \n",
    "        even to have equal chance of using either parent for each trait or \n",
    "        biased to weight the decision based on relative fitness\n",
    "        \"\"\"\n",
    "        offspring = Tree(name, self.mutation_rate)\n",
    "        if mode=='even':\n",
    "            p = None\n",
    "        else:\n",
    "            total_fit = self.fitness + other.fitness\n",
    "            p = np.array([self.fitness / total_fit, other.fitness / total_fit])\n",
    "\n",
    "        offspring.learning_rate = other.learning_rate if either(p) else self.learning_rate\n",
    "\n",
    "        print(self.size, other.size)\n",
    "        for i in range(min(self.size, other.size)):\n",
    "            if self[i].type == other[i].type:\n",
    "                if self[i].type == 'Dense':\n",
    "                    offspring.add_end(DenseNode(self[i].crossover(other[i], p)))\n",
    "                else:\n",
    "                    offspring.add_end(ConvNode(self[i].crossover(other[i], p)))\n",
    "            else:\n",
    "                if either(p):\n",
    "                    config = other[i].config()\n",
    "                    node_type = other[i].type\n",
    "                else:\n",
    "                    config = self[i].config()\n",
    "                    node_type = self[i].type\n",
    "                if node_type == 'Dense':\n",
    "                    offspring.add_end(DenseNode(config))\n",
    "                else:\n",
    "                    offspring.add_end(DenseNode(config))\n",
    "        tail = either(p)\n",
    "        if other.size > self.size and tail:\n",
    "            for i in range(self.size, other.size):\n",
    "                if other[i].type == \"Dense\":\n",
    "                    offspring.add_end(DenseNode(other[i].config()))\n",
    "                else:\n",
    "                    offspring.add_end(ConvNode(other[i].config()))\n",
    "        elif self.size > other.size and not tail:\n",
    "            for i in range(other.size, self.size):\n",
    "                if self[i].type == \"Dense\":\n",
    "                    offspring.add_end(DenseNode(self[i].config()))\n",
    "                else:\n",
    "                    offspring.add_end(ConvNode(self[i].config()))\n",
    "        return offspring\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population(object):\n",
    "    def __init__(self, pop_size=10, cross='even', mutation_rate=0.001):\n",
    "        self.long = 15000 #training examples before done training after short\n",
    "        self.short = 5000 #training examples before cutoff for lower values\n",
    "        self.elites = 3\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.pop_size = pop_size\n",
    "        mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "        train_data = mnist.train.images\n",
    "        train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "        valid_data = mnist.test.images[:int(mnist.test.images.shape[0]*0.5)]\n",
    "        test_data = mnist.test.images[int(mnist.test.images.shape[0]*0.5):]\n",
    "        valid_labels = np.asarray(mnist.test.labels[:int(mnist.test.labels.shape[0]*0.5)], dtype=np.int32)\n",
    "        test_labels = np.asarray(mnist.test.labels[int(mnist.test.labels.shape[0]*0.5):], dtype=np.int32)\n",
    "\n",
    "        # Input for training\n",
    "        self.train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\":train_data},\n",
    "            y=train_labels,\n",
    "            batch_size=100,\n",
    "            num_epochs=None,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Input to get fitness of each individual\n",
    "        self.test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\":valid_data},\n",
    "            y=valid_labels,\n",
    "            num_epochs=1,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        # Input for final testing after evolution\n",
    "        self.results_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\":test_data},\n",
    "            y=test_labels,\n",
    "            num_epochs=1,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        self.pop = []\n",
    "        for i in range(pop_size):\n",
    "            new_tree = Tree('g0-'+str(i), num_nodes=np.random.randint(1,3))\n",
    "            new_tree.show()\n",
    "            self.pop.append(new_tree)\n",
    "        \n",
    "    def evolve(self, eras):\n",
    "        history = []\n",
    "        start = tic()\n",
    "        for e in range(eras):\n",
    "            print(\"Starting Era {}...\".format(e))\n",
    "            era_hist = []\n",
    "            for tree in self.pop:\n",
    "                    tree.train(self.train_fn, steps=self.short)\n",
    "                    if tree.fitness != -10:  #tf error or too long train time\n",
    "                        tree.test(self.test_fn)\n",
    "                    era_hist.append(tree.fitness)\n",
    "                    if tree.fitness > 0.97 and tree.train_time != -1:\n",
    "                        tree.train(self.train_fn, steps=self.long)\n",
    "            history.append(era_hist)\n",
    "            \n",
    "            self.pop = sorted(self.pop, key=lambda x:x.fitness, reverse=True)\n",
    "            print(\"Best fitness for era {}: {:.4f}\".format(e, self.pop[0].fitness))\n",
    "            best = self.pop[:self.elites]\n",
    "            if e < eras-1:\n",
    "                count = len(best)\n",
    "                while len(best) < self.pop_size:\n",
    "                    a, b = np.random.choice(count, 2, replace=False) # use count to prevent crossover with new trees\n",
    "                    new_tree = best[a].crossover(best[b], 'g{}-{}'.format(e, len(best)))\n",
    "                    new_tree.mutate(p=self.mutation_rate)\n",
    "                    new_tree.show()\n",
    "                    best.append(new_tree)\n",
    "                self.pop = best\n",
    "            else:\n",
    "                for tree in best:\n",
    "                    tree.test(self.results_fn)\n",
    "        print(\"Final best fitness after {} eras:\".format(eras))\n",
    "        for tree in best:\n",
    "            print( \"\\t{} = {:.4f}\".format(tree.name, tree.fitness))\n",
    "        print(\"Total training time: {:.4f}\".format(tic()-start))\n",
    "        for i in range(len(self.pop)):\n",
    "            print(\"Tree #{}\".format(i))\n",
    "            self.pop[i].show()\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "---------------------------------------------\n",
      "g0-0\tlr:0.0297\n",
      "\tConv2D\tFilers: 512\tKernel/Stride: 1/1\tActivation: Linear\tDropout: 0.4\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-1\tlr:0.0437\n",
      "\tConv2D\tFilers: 512\tKernel/Stride: 8/2\tActivation: Sigmoid\tDropout: 0.34\n",
      "\tDense\tSize: 128\tActivation: Tanh\tDropout: 0.23\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-2\tlr:0.016\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 5/2\tActivation: Sigmoid\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-3\tlr:0.0127\n",
      "\tDense\tSize: 16\tActivation: Sigmoid\tDropout: 0.44\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-4\tlr:0.1381\n",
      "\tConv2D\tFilers: 128\tKernel/Stride: 1/2\tActivation: Tanh\tDropout: 0.49\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-5\tlr:0.0393\n",
      "\tDense\tSize: 1024\tActivation: Linear\tDropout: 0.08\n",
      "\tDense\tSize: 1024\tActivation: Linear\tDropout: 0.26\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-6\tlr:0.029\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 1/1\tActivation: Tanh\tDropout: 0.14\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-7\tlr:0.139\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 6/1\tActivation: Tanh\tDropout: 0.23\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-8\tlr:0.2\n",
      "\tConv2D\tFilers: 256\tKernel/Stride: 5/1\tActivation: LeakyReLU\tDropout: 0.49\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-9\tlr:0.0745\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 8/4\tActivation: ReLU\tDropout: 0.35\n",
      "---------------------------------------------\n",
      "Starting Era 0...\n",
      "Time to train model \"g0-0\": 62.8607\n",
      "Time to train model \"g0-1\": 22.1093\n",
      "Time to train model \"g0-2\": 5.8172\n",
      "Time to train model \"g0-3\": 4.1579\n",
      "Time to train model \"g0-4\": 11.6991\n",
      "Time to train model \"g0-5\": 5.6053\n",
      "Time to train model \"g0-6\": 8.2728\n",
      "Time to train model \"g0-7\": 10.6087\n",
      "Time to train model \"g0-8\": 44.9368\n",
      "Time to train model \"g0-8\": 133.6873\n",
      "Time to train model \"g0-9\": 4.6540\n",
      "Best fitness for era 0: 0.9676\n",
      "2 1\n",
      "---------------------------------------------\n",
      "g0-3\tlr:0.0745\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 7/1\tActivation: Sigmoid\tDropout: 0.28\n",
      "---------------------------------------------\n",
      "2 1\n",
      "---------------------------------------------\n",
      "g0-4\tlr:0.0511\n",
      "\tConv2D\tFilers: 64\tKernel/Stride: 6/4\tActivation: Linear\tDropout: 0.23\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.27\n",
      "\tDense\tSize: 16\tActivation: LeakyReLU\tDropout: 0.21\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g0-5\tlr:0.1068\n",
      "\tDense\tSize: 32\tActivation: Linear\tDropout: 0.25\n",
      "\tDense\tSize: 256\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 1\n",
      "---------------------------------------------\n",
      "g0-6\tlr:0.0053\n",
      "\tDense\tSize: 1024\tActivation: Linear\tDropout: 0.08\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g0-7\tlr:0.1068\n",
      "\tDense\tSize: 32\tActivation: Sigmoid\tDropout: 0.26\n",
      "\tDense\tSize: 1024\tActivation: ReLU\tDropout: 0.26\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g0-8\tlr:0.002\n",
      "\tDense\tSize: 32\tActivation: Tanh\tDropout: 0.23\n",
      "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.26\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g0-9\tlr:0.2\n",
      "\tDense\tSize: 1024\tActivation: Linear\tDropout: 0\n",
      "\tDense\tSize: 128\tActivation: ReLU\tDropout: 0.26\n",
      "---------------------------------------------\n",
      "Starting Era 1...\n",
      "Time to train model \"g0-7\": 8.9325\n",
      "Time to train model \"g0-7\": 26.9198\n",
      "Time to train model \"g0-9\": 4.6434\n",
      "Time to train model \"g0-5\": 5.7362\n",
      "Time to train model \"g0-3\": 8.9371\n",
      "Time to train model \"g0-4\": 7.8215\n",
      "Time to train model \"g0-5\": 4.4502\n",
      "Time to train model \"g0-6\": 6.6827\n",
      "Time to train model \"g0-7\": 4.8579\n",
      "Time to train model \"g0-8\": 4.4993\n",
      "Time to train model \"g0-9\": 5.1121\n",
      "Best fitness for era 1: 0.9710\n",
      "1 2\n",
      "---------------------------------------------\n",
      "g1-3\tlr:0.0511\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 6/2\tActivation: LeakyReLU\tDropout: 0.21\n",
      "---------------------------------------------\n",
      "1 2\n",
      "---------------------------------------------\n",
      "g1-4\tlr:0.0745\n",
      "\tDense\tSize: 16\tActivation: ReLU\tDropout: 0.28\n",
      "\tDense\tSize: 512\tActivation: Tanh\tDropout: 0.15\n",
      "---------------------------------------------\n",
      "2 1\n",
      "---------------------------------------------\n",
      "g1-5\tlr:0.139\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 5/4\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "2 1\n",
      "---------------------------------------------\n",
      "g1-6\tlr:0.0274\n",
      "\tDense\tSize: 16\tActivation: Sigmoid\tDropout: 0.32\n",
      "---------------------------------------------\n",
      "1 2\n",
      "---------------------------------------------\n",
      "g1-7\tlr:0.0745\n",
      "\tDense\tSize: 16\tActivation: Linear\tDropout: 0.35\n",
      "---------------------------------------------\n",
      "2 1\n",
      "---------------------------------------------\n",
      "g1-8\tlr:0.0274\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 6/1\tActivation: ReLU\tDropout: 0.33\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "1 2\n",
      "---------------------------------------------\n",
      "g1-9\tlr:0.2\n",
      "\tDense\tSize: 16\tActivation: ReLU\tDropout: 0.35\n",
      "\tDense\tSize: 64\tActivation: Sigmoid\tDropout: 0.27\n",
      "\tDense\tSize: 128\tActivation: Sigmoid\tDropout: 0.45\n",
      "---------------------------------------------\n",
      "Starting Era 2...\n",
      "Time to train model \"g0-7\": 10.7163\n",
      "Time to train model \"g0-7\": 34.4029\n",
      "Time to train model \"g0-9\": 4.8311\n",
      "Time to train model \"g0-9\": 16.1296\n",
      "Time to train model \"g0-9\": 4.8602\n",
      "Time to train model \"g0-9\": 13.9595\n",
      "Time to train model \"g1-3\": 5.3434\n",
      "Time to train model \"g1-4\": 7.2480\n",
      "Time to train model \"g1-5\": 4.7917\n",
      "Time to train model \"g1-6\": 4.7956\n",
      "Time to train model \"g1-7\": 4.2162\n",
      "Time to train model \"g1-8\": 10.9763\n",
      "Time to train model \"g1-8\": 34.5778\n",
      "Time to train model \"g1-9\": 4.8806\n",
      "Best fitness for era 2: 0.9728\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g2-3\tlr:0.0274\n",
      "\tDense\tSize: 1024\tActivation: Linear\tDropout: 0.04\n",
      "\tDense\tSize: 32\tActivation: LeakyReLU\tDropout: 0.35\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g2-4\tlr:0.2\n",
      "\tDense\tSize: 128\tActivation: Sigmoid\tDropout: 0.33\n",
      "\tDense\tSize: 32\tActivation: Sigmoid\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g2-5\tlr:0.2\n",
      "\tDense\tSize: 512\tActivation: Linear\tDropout: 0\n",
      "\tDense\tSize: 128\tActivation: Linear\tDropout: 0.3\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g2-6\tlr:0.139\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 6/1\tActivation: ReLU\tDropout: 0.23\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g2-7\tlr:0.0511\n",
      "\tDense\tSize: 32\tActivation: Tanh\tDropout: 0.21\n",
      "\tDense\tSize: 128\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g2-8\tlr:0.0101\n",
      "\tDense\tSize: 16\tActivation: Sigmoid\tDropout: 0.32\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g2-9\tlr:0.0274\n",
      "\tDense\tSize: 1024\tActivation: Linear\tDropout: 0\n",
      "\tDense\tSize: 128\tActivation: ReLU\tDropout: 0.25\n",
      "---------------------------------------------\n",
      "Starting Era 3...\n",
      "Time to train model \"g0-7\": 8.6164\n",
      "Time to train model \"g0-7\": 27.1921\n",
      "Time to train model \"g1-8\": 11.6278\n",
      "Time to train model \"g1-8\": 25.0149\n",
      "Time to train model \"g0-9\": 4.8685\n",
      "Time to train model \"g0-9\": 21.7196\n",
      "Time to train model \"g2-3\": 5.1554\n",
      "Time to train model \"g2-4\": 4.6140\n",
      "Time to train model \"g2-5\": 5.7475\n",
      "Time to train model \"g2-6\": 8.5597\n",
      "Time to train model \"g2-6\": 24.0897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train model \"g2-7\": 6.6848\n",
      "Time to train model \"g2-8\": 4.8410\n",
      "Time to train model \"g2-9\": 4.7677\n",
      "Best fitness for era 3: 0.9812\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g3-3\tlr:0.0274\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 5/1\tActivation: Sigmoid\tDropout: 0.24\n",
      "\tDense\tSize: 16\tActivation: Linear\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g3-4\tlr:0.0511\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g3-5\tlr:0.0511\n",
      "\tConv2D\tFilers: 64\tKernel/Stride: 6/2\tActivation: ReLU\tDropout: 0.33\n",
      "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g3-6\tlr:0.0745\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 8/2\tActivation: ReLU\tDropout: 0.23\n",
      "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g3-7\tlr:0.2\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 3/1\tActivation: Linear\tDropout: 0.23\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g3-8\tlr:0.0511\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 3/1\tActivation: ReLU\tDropout: 0.33\n",
      "\tDense\tSize: 16\tActivation: Tanh\tDropout: 0.31\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g3-9\tlr:0.139\n",
      "\tConv2D\tFilers: 64\tKernel/Stride: 6/2\tActivation: Tanh\tDropout: 0.23\n",
      "\tDense\tSize: 16\tActivation: LeakyReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "Starting Era 4...\n",
      "Time to train model \"g1-8\": 8.5550\n",
      "Time to train model \"g1-8\": 25.0734\n",
      "Time to train model \"g2-6\": 9.3294\n",
      "Time to train model \"g2-6\": 23.9857\n",
      "Time to train model \"g0-7\": 11.4886\n",
      "Time to train model \"g0-7\": 25.6230\n",
      "Time to train model \"g3-3\": 10.2421\n",
      "Time to train model \"g3-4\": 4.2489\n",
      "Time to train model \"g3-5\": 8.1444\n",
      "Time to train model \"g3-5\": 20.5289\n",
      "Time to train model \"g3-6\": 5.5616\n",
      "Time to train model \"g3-6\": 24.1526\n",
      "Time to train model \"g3-7\": 10.9872\n",
      "Time to train model \"g3-8\": 11.1524\n",
      "Time to train model \"g3-9\": 9.3455\n",
      "Best fitness for era 4: 0.9832\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g4-3\tlr:0.0745\n",
      "\tConv2D\tFilers: 128\tKernel/Stride: 10/2\tActivation: Tanh\tDropout: 0.23\n",
      "\tDense\tSize: 16\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g4-4\tlr:0.0274\n",
      "\tConv2D\tFilers: 128\tKernel/Stride: 6/1\tActivation: ReLU\tDropout: 0.24\n",
      "\tDense\tSize: 16\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g4-5\tlr:0.139\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 5/1\tActivation: LeakyReLU\tDropout: 0.33\n",
      "\tDense\tSize: 16\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g4-6\tlr:0.0511\n",
      "\tConv2D\tFilers: 64\tKernel/Stride: 7/1\tActivation: ReLU\tDropout: 0.23\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g4-7\tlr:0.0274\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 7/2\tActivation: ReLU\tDropout: 0.14\n",
      "\tDense\tSize: 128\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g4-8\tlr:0.139\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 6/1\tActivation: Sigmoid\tDropout: 0.23\n",
      "\tDense\tSize: 64\tActivation: Linear\tDropout: 0.29\n",
      "\tDense\tSize: 128\tActivation: LeakyReLU\tDropout: 0.47\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g4-9\tlr:0.0745\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 8/3\tActivation: ReLU\tDropout: 0.23\n",
      "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "Starting Era 5...\n",
      "Time to train model \"g1-8\": 8.6030\n",
      "Time to train model \"g1-8\": 29.6434\n",
      "Time to train model \"g2-6\": 9.8664\n",
      "Time to train model \"g2-6\": 31.5419\n",
      "Time to train model \"g3-6\": 5.5249\n",
      "Time to train model \"g3-6\": 27.7819\n",
      "Time to train model \"g4-3\": 7.6697\n",
      "Time to train model \"g4-4\": 19.2921\n",
      "Time to train model \"g4-4\": 55.5632\n",
      "Time to train model \"g4-5\": 8.0854\n",
      "Time to train model \"g4-5\": 23.4987\n",
      "Time to train model \"g4-6\": 14.8367\n",
      "Time to train model \"g4-6\": 37.8142\n",
      "Time to train model \"g4-7\": 5.3817\n",
      "ERROR:tensorflow:Model diverged with loss = NaN.\n",
      "TensorFlow failure --\n",
      "---------------------------------------------\n",
      "g4-8\tlr:0.139\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 6/1\tActivation: Sigmoid\tDropout: 0.23\n",
      "\tDense\tSize: 64\tActivation: Linear\tDropout: 0.29\n",
      "\tDense\tSize: 128\tActivation: LeakyReLU\tDropout: 0.47\n",
      "---------------------------------------------\n",
      "Time to train model \"g4-9\": 5.2860\n",
      "Time to train model \"g4-9\": 25.1457\n",
      "Best fitness for era 5: 0.9856\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g5-3\tlr:0.0101\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 6/1\tActivation: ReLU\tDropout: 0.23\n",
      "\tDense\tSize: 16\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g5-4\tlr:0.2\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 6/1\tActivation: ReLU\tDropout: 0.27\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g5-5\tlr:0.0274\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 5/1\tActivation: ReLU\tDropout: 0.33\n",
      "\tDense\tSize: 32\tActivation: LeakyReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g5-6\tlr:0.139\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 8/1\tActivation: ReLU\tDropout: 0.33\n",
      "\tDense\tSize: 16\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g5-7\tlr:0.0511\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 8/2\tActivation: Linear\tDropout: 0.22\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g5-8\tlr:0.139\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 6/1\tActivation: LeakyReLU\tDropout: 0.22\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g5-9\tlr:0.0274\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 6/1\tActivation: ReLU\tDropout: 0.23\n",
      "\tDense\tSize: 32\tActivation: Sigmoid\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "Starting Era 6...\n",
      "Time to train model \"g3-6\": 9.5684\n",
      "Time to train model \"g3-6\": 28.0046\n",
      "Time to train model \"g2-6\": 8.4537\n",
      "Time to train model \"g2-6\": 25.9405\n",
      "Time to train model \"g1-8\": 8.5611\n",
      "Time to train model \"g1-8\": 24.9345\n",
      "Time to train model \"g5-3\": 10.2771\n",
      "Time to train model \"g5-4\": 7.1232\n",
      "Time to train model \"g5-4\": 26.5769\n",
      "Time to train model \"g5-5\": 7.4045\n",
      "Time to train model \"g5-6\": 8.5574\n",
      "Time to train model \"g5-6\": 28.2986\n",
      "Time to train model \"g5-7\": 8.8018\n",
      "Time to train model \"g5-8\": 10.1086\n",
      "Time to train model \"g5-8\": 33.1699\n",
      "Time to train model \"g5-9\": 8.7526\n",
      "Best fitness for era 6: 0.9864\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g6-3\tlr:0.0274\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 6/1\tActivation: Sigmoid\tDropout: 0.34\n",
      "\tDense\tSize: 128\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g6-4\tlr:0.0101\n",
      "\tConv2D\tFilers: 64\tKernel/Stride: 8/4\tActivation: ReLU\tDropout: 0.23\n",
      "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.31\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g6-5\tlr:0.0274\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 7/1\tActivation: ReLU\tDropout: 0.33\n",
      "\tDense\tSize: 16\tActivation: Sigmoid\tDropout: 0.32\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g6-6\tlr:0.0274\n",
      "\tConv2D\tFilers: 64\tKernel/Stride: 6/2\tActivation: ReLU\tDropout: 0.33\n",
      "\tDense\tSize: 128\tActivation: Tanh\tDropout: 0.16\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g6-7\tlr:0.0274\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 6/2\tActivation: Linear\tDropout: 0.23\n",
      "\tDense\tSize: 128\tActivation: Sigmoid\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g6-8\tlr:0.0274\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 7/1\tActivation: Sigmoid\tDropout: 0.27\n",
      "\tDense\tSize: 32\tActivation: Tanh\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g6-9\tlr:0.0274\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 9/1\tActivation: Tanh\tDropout: 0.31\n",
      "\tDense\tSize: 16\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "Starting Era 7...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train model \"g3-6\": 7.1593\n",
      "Time to train model \"g3-6\": 18.3252\n",
      "Time to train model \"g2-6\": 7.1596\n",
      "Time to train model \"g2-6\": 20.8614\n",
      "Time to train model \"g1-8\": 10.7923\n",
      "Time to train model \"g1-8\": 27.8765\n",
      "Time to train model \"g6-3\": 14.0675\n",
      "Time to train model \"g6-4\": 5.3608\n",
      "Time to train model \"g6-5\": 8.4191\n",
      "Time to train model \"g6-6\": 9.6428\n",
      "Time to train model \"g6-7\": 6.4660\n",
      "Time to train model \"g6-8\": 10.8492\n",
      "Time to train model \"g6-9\": 9.8563\n",
      "Best fitness for era 7: 0.9876\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g7-3\tlr:0.0745\n",
      "\tConv2D\tFilers: 64\tKernel/Stride: 8/1\tActivation: ReLU\tDropout: 0.24\n",
      "\tDense\tSize: 64\tActivation: LeakyReLU\tDropout: 0.26\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g7-4\tlr:0.0745\n",
      "\tConv2D\tFilers: 256\tKernel/Stride: 8/1\tActivation: Tanh\tDropout: 0.3\n",
      "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g7-5\tlr:0.0745\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 8/2\tActivation: ReLU\tDropout: 0.23\n",
      "\tDense\tSize: 256\tActivation: Tanh\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g7-6\tlr:0.0274\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 7/2\tActivation: ReLU\tDropout: 0.26\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g7-7\tlr:0.0745\n",
      "\tConv2D\tFilers: 64\tKernel/Stride: 7/2\tActivation: ReLU\tDropout: 0.31\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g7-8\tlr:0.2\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 6/1\tActivation: Sigmoid\tDropout: 0.33\n",
      "\tDense\tSize: 32\tActivation: Tanh\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g7-9\tlr:0.0511\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 6/2\tActivation: ReLU\tDropout: 0.23\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "Starting Era 8...\n",
      "Time to train model \"g3-6\": 5.5682\n",
      "Time to train model \"g3-6\": 20.1734\n",
      "Time to train model \"g2-6\": 8.5179\n",
      "Time to train model \"g2-6\": 20.4807\n",
      "Time to train model \"g1-8\": 10.5648\n",
      "Time to train model \"g1-8\": 28.4835\n",
      "Time to train model \"g7-3\": 12.8840\n",
      "Time to train model \"g7-3\": 38.5204\n",
      "Time to train model \"g7-4\": 30.1396\n",
      "Time to train model \"g7-5\": 6.9750\n",
      "Time to train model \"g7-5\": 24.9986\n",
      "Time to train model \"g7-6\": 9.0718\n",
      "Time to train model \"g7-7\": 6.6720\n",
      "Time to train model \"g7-7\": 21.0220\n",
      "Time to train model \"g7-8\": 11.1240\n",
      "Time to train model \"g7-9\": 7.3467\n",
      "Time to train model \"g7-9\": 26.2089\n",
      "Best fitness for era 8: 0.9864\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g8-3\tlr:0.0274\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 7/1\tActivation: Linear\tDropout: 0.22\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.31\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g8-4\tlr:0.139\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 6/1\tActivation: Linear\tDropout: 0.28\n",
      "\tDense\tSize: 128\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g8-5\tlr:0.139\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 8/1\tActivation: ReLU\tDropout: 0.31\n",
      "\tDense\tSize: 32\tActivation: Tanh\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g8-6\tlr:0.139\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 8/2\tActivation: Linear\tDropout: 0.23\n",
      "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.36\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g8-7\tlr:0.139\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 9/1\tActivation: ReLU\tDropout: 0.27\n",
      "\tDense\tSize: 128\tActivation: LeakyReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g8-8\tlr:0.0274\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 7/1\tActivation: LeakyReLU\tDropout: 0.23\n",
      "\tDense\tSize: 128\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "2 2\n",
      "---------------------------------------------\n",
      "g8-9\tlr:0.0101\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 8/2\tActivation: ReLU\tDropout: 0.33\n",
      "\tDense\tSize: 16\tActivation: Linear\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "Starting Era 9...\n",
      "Time to train model \"g3-6\": 10.7432\n",
      "Time to train model \"g3-6\": 24.8001\n",
      "Time to train model \"g2-6\": 8.5302\n",
      "Time to train model \"g2-6\": 27.4505\n",
      "Time to train model \"g1-8\": 11.2360\n",
      "Time to train model \"g1-8\": 26.3349\n",
      "Time to train model \"g8-3\": 6.8643\n",
      "Time to train model \"g8-4\": 9.8495\n",
      "Time to train model \"g8-4\": 34.2148\n",
      "Time to train model \"g8-5\": 6.6685\n",
      "Time to train model \"g8-5\": 27.1361\n",
      "Time to train model \"g8-6\": 5.5094\n",
      "Time to train model \"g8-7\": 9.1901\n",
      "Time to train model \"g8-7\": 28.3504\n",
      "Time to train model \"g8-8\": 8.1171\n",
      "Time to train model \"g8-9\": 5.3645\n",
      "Best fitness for era 9: 0.9870\n",
      "Final best fitness after 10 eras:\n",
      "\tg3-6 = 0.9964\n",
      "\tg2-6 = 0.9952\n",
      "\tg1-8 = 0.9966\n",
      "Total training time: 2225.2664\n",
      "Tree #0\n",
      "---------------------------------------------\n",
      "g3-6\tlr:0.0745\n",
      "\tFitness: 0.996399998664856\tAccuracy: 0.996399998664856\tLoss: 0.015239628963172436\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 8/2\tActivation: ReLU\tDropout: 0.23\n",
      "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "Tree #1\n",
      "---------------------------------------------\n",
      "g2-6\tlr:0.139\n",
      "\tFitness: 0.995199978351593\tAccuracy: 0.995199978351593\tLoss: 0.028092775493860245\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 6/1\tActivation: ReLU\tDropout: 0.23\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "Tree #2\n",
      "---------------------------------------------\n",
      "g1-8\tlr:0.0274\n",
      "\tFitness: 0.9965999722480774\tAccuracy: 0.9965999722480774\tLoss: 0.01783893257379532\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 6/1\tActivation: ReLU\tDropout: 0.33\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "Tree #3\n",
      "---------------------------------------------\n",
      "g8-7\tlr:0.139\n",
      "\tFitness: 0.9833999872207642\tAccuracy: 0.9833999872207642\tLoss: 0.04719638079404831\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 9/1\tActivation: ReLU\tDropout: 0.27\n",
      "\tDense\tSize: 128\tActivation: LeakyReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "Tree #4\n",
      "---------------------------------------------\n",
      "g8-5\tlr:0.139\n",
      "\tFitness: 0.9824000000953674\tAccuracy: 0.9824000000953674\tLoss: 0.047691211104393005\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 8/1\tActivation: ReLU\tDropout: 0.31\n",
      "\tDense\tSize: 32\tActivation: Tanh\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "Tree #5\n",
      "---------------------------------------------\n",
      "g8-4\tlr:0.139\n",
      "\tFitness: 0.9733999967575073\tAccuracy: 0.9733999967575073\tLoss: 0.09432865679264069\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 6/1\tActivation: Linear\tDropout: 0.28\n",
      "\tDense\tSize: 128\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "Tree #6\n",
      "---------------------------------------------\n",
      "g8-8\tlr:0.0274\n",
      "\tFitness: 0.9696000218391418\tAccuracy: 0.9696000218391418\tLoss: 0.09851422160863876\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 7/1\tActivation: LeakyReLU\tDropout: 0.23\n",
      "\tDense\tSize: 128\tActivation: ReLU\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "Tree #7\n",
      "---------------------------------------------\n",
      "g8-6\tlr:0.139\n",
      "\tFitness: 0.9599999785423279\tAccuracy: 0.9599999785423279\tLoss: 0.12758079171180725\n",
      "\tConv2D\tFilers: 32\tKernel/Stride: 8/2\tActivation: Linear\tDropout: 0.23\n",
      "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.36\n",
      "---------------------------------------------\n",
      "Tree #8\n",
      "---------------------------------------------\n",
      "g8-9\tlr:0.0101\n",
      "\tFitness: 0.949400007724762\tAccuracy: 0.949400007724762\tLoss: 0.17102724313735962\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 8/2\tActivation: ReLU\tDropout: 0.33\n",
      "\tDense\tSize: 16\tActivation: Linear\tDropout: 0.29\n",
      "---------------------------------------------\n",
      "Tree #9\n",
      "---------------------------------------------\n",
      "g8-3\tlr:0.0274\n",
      "\tFitness: 0.9380000233650208\tAccuracy: 0.9380000233650208\tLoss: 0.2073480784893036\n",
      "\tConv2D\tFilers: 16\tKernel/Stride: 7/1\tActivation: Linear\tDropout: 0.22\n",
      "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.31\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pool = Population(mutation_rate=0.5)\n",
    "hist = pool.evolve(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total training time: 903.6920\n",
    "Tree #0\n",
    "---------------------------------------------\n",
    "g1-8\tlr:0.0236\n",
    "\tFitness: 0.9904000163078308\tAccuracy: 0.9904000163078308\tLoss: 0.044565413147211075\n",
    "\tSize: 256\tActivation: ReLU\tDropout: 0.43\n",
    "\tSize: 64\tActivation: LeakyReLU\tDropout: 0.13\n",
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Final best fitness after 10 eras:\n",
    "\tg0-6 = 0.9944\n",
    "\tg2-6 = 0.9928\n",
    "\tg0-5 = 0.9884\n",
    "Total training time: 1194.9157\n",
    "Tree #0\n",
    "---------------------------------------------\n",
    "g0-6\tlr:0.0596\n",
    "\tFitness: 0.9944000244140625\tAccuracy: 0.9944000244140625\tLoss: 0.022790133953094482\n",
    "\tConv2D\tFilers: 128\tKernel/Stride: 8/4\tActivation: ReLU\tDropout: 0.47\n",
    "\tDense\tSize: 16\tActivation: ReLU\tDropout: 0.2\n",
    "---------------------------------------------\n",
    "Tree #1\n",
    "---------------------------------------------\n",
    "g2-6\tlr:0.162\n",
    "\tFitness: 0.9927999973297119\tAccuracy: 0.9927999973297119\tLoss: 0.03554263338446617\n",
    "\tDense\tSize: 256\tActivation: ReLU\tDropout: 0.46\n",
    "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.04\n",
    "---------------------------------------------\n",
    "Tree #2\n",
    "---------------------------------------------\n",
    "g0-5\tlr:0.0596\n",
    "\tFitness: 0.9883999824523926\tAccuracy: 0.9883999824523926\tLoss: 0.041383564472198486\n",
    "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Final best fitness after 10 eras:\n",
    "\tg3-6 = 0.9964\n",
    "\tg2-6 = 0.9952\n",
    "\tg1-8 = 0.9966\n",
    "Total training time: 2225.2664\n",
    "Tree #0\n",
    "---------------------------------------------\n",
    "g3-6\tlr:0.0745\n",
    "\tFitness: 0.996399998664856\tAccuracy: 0.996399998664856\tLoss: 0.015239628963172436\n",
    "\tConv2D\tFilers: 32\tKernel/Stride: 8/2\tActivation: ReLU\tDropout: 0.23\n",
    "\tDense\tSize: 64\tActivation: ReLU\tDropout: 0.29\n",
    "---------------------------------------------\n",
    "Tree #1\n",
    "---------------------------------------------\n",
    "g2-6\tlr:0.139\n",
    "\tFitness: 0.995199978351593\tAccuracy: 0.995199978351593\tLoss: 0.028092775493860245\n",
    "\tConv2D\tFilers: 16\tKernel/Stride: 6/1\tActivation: ReLU\tDropout: 0.23\n",
    "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.27\n",
    "---------------------------------------------\n",
    "Tree #2\n",
    "---------------------------------------------\n",
    "g1-8\tlr:0.0274\n",
    "\tFitness: 0.9965999722480774\tAccuracy: 0.9965999722480774\tLoss: 0.01783893257379532\n",
    "\tConv2D\tFilers: 32\tKernel/Stride: 6/1\tActivation: ReLU\tDropout: 0.33\n",
    "\tDense\tSize: 32\tActivation: ReLU\tDropout: 0.29\n",
    "---------------------------------------------\n",
    "Tree #3\n",
    "---------------------------------------------\n",
    "g8-7\tlr:0.139\n",
    "\tFitness: 0.9833999872207642\tAccuracy: 0.9833999872207642\tLoss: 0.04719638079404831\n",
    "\tConv2D\tFilers: 16\tKernel/Stride: 9/1\tActivation: ReLU\tDropout: 0.27\n",
    "\tDense\tSize: 128\tActivation: LeakyReLU\tDropout: 0.29\n",
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"hist5.npy\", np.array(hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_name = \"hist5\"\n",
    "hist = np.load(hist_name+'.npy')\n",
    "x = []\n",
    "y = []\n",
    "for i in range(len(hist)):\n",
    "    for j in range(len(hist[i])):\n",
    "        y.append(max(hist[i][j], 0))\n",
    "        x.append(i)\n",
    "plt.title(\"Accuracy of Individuals over Time\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.scatter(x, y)\n",
    "plt.xticks(range(0,10))\n",
    "plt.savefig(hist_name+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
