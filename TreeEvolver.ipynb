{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanmullan/Code/.virtualenvs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from timeit import default_timer as tic\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antifix(x):\n",
    "    \"\"\"Similar to numpy's fix function, but rounds away from 0\"\"\"\n",
    "    return (np.sign(x) * np.ceil(np.absolute(x))).astype(int)\n",
    "    \n",
    "\n",
    "def shift(count=None):\n",
    "    \"\"\"Get an array of ints from a normal distribution centered around 0 with a stddev of 1\n",
    "    --returns a single int rather than an array if count is None\n",
    "    \"\"\"\n",
    "    return constrain(antifix(np.random.normal(size=count)), -3, 3)\n",
    "\n",
    "def either(p=None):\n",
    "    \"\"\"Shortcut for a boolean choice with probabilities\"\"\"\n",
    "    return np.random.choice(2, p=p)\n",
    "\n",
    "def constrain(x, low, high, decimals=2):\n",
    "    \"\"\"Constrains the value to the given range (inclusive) and rounds to number of decimals\"\"\"\n",
    "    value = None\n",
    "    if x < low:\n",
    "        value = low\n",
    "    elif x > high:\n",
    "        value = high\n",
    "    else:\n",
    "        value = x\n",
    "    return np.around(value, decimals)\n",
    "    \n",
    "def distrib(x):\n",
    "    \"\"\"Softmax, but doubles values to increase disparity\"\"\"\n",
    "    x_exp = np.exp(np.array(x) * 2)\n",
    "    return x_exp / x_exp.sum()\n",
    "\n",
    "def init_drop(p=None):\n",
    "    \"\"\"Return a random initial dropout\"\"\"\n",
    "    return np.around(np.random.uniform(0, 0.5), 2)\n",
    "\n",
    "activations = [None, tf.nn.tanh, tf.nn.relu, tf.nn.leaky_relu, tf.nn.sigmoid]\n",
    "def init_act(p=None):\n",
    "    \"\"\"Return a random initial activation function\"\"\"\n",
    "    return np.random.choice(np.arange(len(activations)), p=p)\n",
    "    \n",
    "def init_hsize():\n",
    "    \"\"\"Return a random initial fully-connected layer size\n",
    "    values are [4,10] since hidden size will be 2^x for whatever x is returned\"\"\"\n",
    "    return np.random.randint(4,10 + 1)\n",
    "\n",
    "def init_lr():\n",
    "    return constrain(np.random.exponential(scale=0.09), 0.001, 0.3, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"V2.0 - Tree-like structure, but no branching yet\"\"\"\n",
    "class Node(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.child = None  # will only be 1 child for this version\n",
    "        self.depth = 0\n",
    "\n",
    "    def __iadd__(self, node):\n",
    "        if self.child:\n",
    "            node.depth += 1\n",
    "            self.child += node\n",
    "        else:\n",
    "            self.child = node\n",
    "        return self\n",
    "    \n",
    "    def get(self, depth):\n",
    "        if self.child is None:\n",
    "            return None\n",
    "        if depth==0:\n",
    "            return self.child\n",
    "        else:\n",
    "            return self.child.get(depth-1)\n",
    "        \n",
    "class DenseNode(Node):\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        Node.__init__(self)\n",
    "        \n",
    "        if config:\n",
    "            self.dropout = config[0]\n",
    "            self.activation_func = config[1]\n",
    "            self.size = config[2]\n",
    "        else:\n",
    "            self.dropout = init_drop()\n",
    "            self.activation_func = init_act()\n",
    "            self.size = init_hsize()\n",
    "        \n",
    "        self.type = \"Dense\"\n",
    "            \n",
    "    def show(self):\n",
    "        acts = ['Linear','Tanh','ReLU','LeakyReLU','Sigmoid']\n",
    "        print(\"\\tSize: {}\\tActivation: {}\\tDropout: {}\".format(2**self.size, acts[self.activation_func], self.dropout))\n",
    "        if(self.child):\n",
    "            self.child.show()\n",
    "            \n",
    "    def __call__(self, x, mode):\n",
    "        dense = tf.layers.dense(inputs=x, units=2**self.size, activation=activations[self.activation_func])\n",
    "        if self.dropout != 0:\n",
    "                dense = tf.layers.dropout(inputs=dense, rate=self.dropout, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        if self.child:\n",
    "            return self.child(dense, mode)\n",
    "        return dense\n",
    "    \n",
    "    def trim(self, depth):\n",
    "        if depth==0:\n",
    "            self.child = None\n",
    "        else:\n",
    "            self.child.trim(depth-1)\n",
    "    \n",
    "    def mutate(self, mutation_rate):\n",
    "        if np.random.rand() < mutation_rate:\n",
    "            self.size = constrain(self.size + shift(), 4, 10)\n",
    "            \n",
    "        if np.random.rand() < mutation_rate:\n",
    "            self.dropout = constrain(self.dropout + np.random.normal(scale=0.05), 0, 0.5)\n",
    "            \n",
    "        if np.random.rand() < mutation_rate:\n",
    "            self.activation_func = init_act()\n",
    "            \n",
    "        if self.child:\n",
    "            self.child.mutate(mutation_rate)\n",
    "            \n",
    "    def crossover(self, other, p):\n",
    "        config = [self.dropout, self.activation_func, self.size]\n",
    "        if either(p):\n",
    "            config[0] = other.dropout\n",
    "        if either(p):\n",
    "            config[1] = other.activation_func\n",
    "        if either(p):\n",
    "            config[2] = other.size\n",
    "        return config\n",
    "    \n",
    "    def config(self):\n",
    "        return [self.dropout, self.activation_func, self.size]\n",
    "    \n",
    "    \n",
    "class Tree(object):\n",
    "    \"\"\"Acts as the root as well\"\"\"\n",
    "    def __init__(self, name, mutation_rate=0.1, grow_prob=0.1, shrink_prob=0.1, num_nodes=0, load=False):\n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "        self.child = None  # will only be 1 child for now\n",
    "        self.name = name\n",
    "        \n",
    "        self.size = 0\n",
    "        self.fitness = 0\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.grow_prob = grow_prob\n",
    "        self.shrink_prob = shrink_prob\n",
    "        self.age = 0  # Total number of epochs seen\n",
    "        self.accuracy = -1\n",
    "        self.loss = -1\n",
    "        self.train_time = -1\n",
    "        \n",
    "        self.learning_rate = init_lr()#0.001\n",
    "\n",
    "        for i in range(num_nodes):\n",
    "            self += DenseNode()\n",
    "            \n",
    "        if load:\n",
    "            self.classifier = tf.estimator.Estimator(\n",
    "                model_fn=self.model_fn,\n",
    "                model_dir=\"./\"+self.name\n",
    "            )\n",
    "        else:\n",
    "            self.classifier = tf.estimator.Estimator(\n",
    "                model_fn=self.model_fn\n",
    "            )\n",
    "            \n",
    "    def show(self):\n",
    "        print(\"---------------------------------------------\")\n",
    "        print(self.name+\"\\tlr:{}\".format(self.learning_rate))\n",
    "        if(self.fitness!=0):\n",
    "            print(\"\\tFitness: {}\\tAccuracy: {}\\tLoss: {}\".format(self.fitness, self.accuracy, self.loss))\n",
    "        self.child.show()\n",
    "        print(\"---------------------------------------------\")\n",
    "\n",
    "    def update_fitness(self):\n",
    "        self.fitness = self.accuracy\n",
    "    \n",
    "    def name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def train(self, input_fn, verbose=False, steps=20000):\n",
    "        logging_hooks = None\n",
    "        if verbose:\n",
    "            logged_vars = {\"probabilities\": \"softmax_tensor\"}\n",
    "            logging_hooks = [tf.train.LoggingTensorHook(tensors=logged_vars, every_n_iter=2000)]\n",
    "\n",
    "        start = tic()\n",
    "        self.classifier.train(\n",
    "            input_fn=input_fn,\n",
    "            steps=steps,\n",
    "            hooks=logging_hooks\n",
    "        )\n",
    "        self.train_time = tic()-start\n",
    "        self.age += steps\n",
    "        print(\"Time to train model \\\"{}\\\": {:.4f}\".format(self.name, self.train_time))\n",
    "        \n",
    "    def test(self, input_fn):\n",
    "        results = self.classifier.evaluate(input_fn)\n",
    "        self.accuracy = results['accuracy']\n",
    "        self.age = results['global_step']\n",
    "        self.loss = results['loss']\n",
    "        self.update_fitness()\n",
    "        return results\n",
    "        \n",
    "    def model_fn(self, features, labels, mode):\n",
    "        input_layer = tf.reshape(features[\"x\"], [-1, 784])\n",
    "        \n",
    "        hidden = self.child(input_layer, mode)\n",
    "        \n",
    "        logits =tf.layers.dense(inputs=hidden, units=10)\n",
    "        \n",
    "        predictions = {\n",
    "            \"classes\": tf.argmax(input=logits, axis=1),\n",
    "            \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        }\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "        \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate)\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step()\n",
    "            )\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "        \n",
    "        eval_metric_ops = {\n",
    "            \"accuracy\":tf.metrics.accuracy(\n",
    "                labels=labels,\n",
    "                predictions=predictions['classes']\n",
    "            )\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metric_ops\n",
    "        )\n",
    "        \n",
    "    def __call__(self):\n",
    "        result = self.children[0](self.x)\n",
    "        logits = tf.layers.dense(inputs=result, units=10, name=\"logits\")\n",
    "        \n",
    "        classes = tf.argmax(input=logits, axis=1)\n",
    "        probs = tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        \n",
    "    def __iadd__(self, node):  # +=\n",
    "        self.size += 1\n",
    "        if self.child:\n",
    "            node.depth += 1\n",
    "            self.child += node\n",
    "        else:\n",
    "            self.child = node\n",
    "        return self\n",
    "    \n",
    "    def get_mode(self):\n",
    "        return self.mode\n",
    "    \n",
    "    def __getitem__(self, depth):\n",
    "        if self.child is None:\n",
    "            raise IndexError(\"There is no layer at depth {}.\".format(depth))\n",
    "        if depth==0:\n",
    "            return self.child\n",
    "        else:\n",
    "            result = self.child.get(depth-1)\n",
    "            if result is None:\n",
    "                raise IndexError(\"There is no layer at depth {}.\".format(depth))\n",
    "            return result\n",
    "        \n",
    "    def mutate(self):\n",
    "        if np.random.rand() < self.mutation_rate:\n",
    "            self.learning_rate = constrain(np.exp(np.log(self.learning_rate) + shift()), 0.0001, 0.5, decimals=4)\n",
    "        if either(np.array([1-self.shrink_prob, self.shrink_prob])):\n",
    "            self.child.trim(self.size-1)\n",
    "        if either(np.array([1-self.grow_prob, self.grow_prob])):\n",
    "            self += DenseNode()\n",
    "        if self.child:\n",
    "            self.child.mutate(self.mutation_rate)\n",
    "            \n",
    "    def crossover(self, other, name, mode='even'):\n",
    "        \"\"\"Crossover to get offspring of two trees\n",
    "        mode -- either even or biased. \n",
    "        even to have equal chance of using either parent for each trait or \n",
    "        biased to weight the decision based on relative fitness\n",
    "        \"\"\"\n",
    "        offspring = Tree(name, self.mutation_rate)\n",
    "        if mode=='even':\n",
    "            p = None\n",
    "        else:\n",
    "            total_fit = self.fitness + other.fitness\n",
    "            p = np.array([self.fitness / total_fit, other.fitness / total_fit])\n",
    "\n",
    "        offspring.learning_rate = other.learning_rate if either(p) else self.learning_rate\n",
    "\n",
    "        for i in range(min(self.size, other.size)):\n",
    "            offspring += DenseNode(self[i].crossover(other[i], p))\n",
    "        tail = either(p)\n",
    "        if other.size > self.size and tail:\n",
    "            for i in range(self.size, other.size):\n",
    "                offspring += DenseNode(other[i].config())\n",
    "        elif self.size > other.size and not tail:\n",
    "            for i in range(other.size, self.size):\n",
    "                offspring += DenseNode(self[i].config())\n",
    "        return offspring\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population(object):\n",
    "    def __init__(self, pop_size=10, cross='even', mutation_rate=0.001):\n",
    "        self.adult = 20000\n",
    "        self.elder = 40000\n",
    "        self.era_len = 5000\n",
    "#         self.era_len = 20000\n",
    "        self.elites = 1\n",
    "        self.deaths = 3\n",
    "\n",
    "        mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "        train_data = mnist.train.images\n",
    "        train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "        valid_data = mnist.test.images[:int(mnist.test.images.shape[0]*0.5)]\n",
    "        test_data = mnist.test.images[int(mnist.test.images.shape[0]*0.5):]\n",
    "        valid_labels = np.asarray(mnist.test.labels[:int(mnist.test.labels.shape[0]*0.5)], dtype=np.int32)\n",
    "        test_labels = np.asarray(mnist.test.labels[int(mnist.test.labels.shape[0]*0.5):], dtype=np.int32)\n",
    "\n",
    "        # Input for training\n",
    "        self.train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\":train_data},\n",
    "            y=train_labels,\n",
    "            batch_size=100,\n",
    "            num_epochs=None,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Input to get fitness of each individual\n",
    "        self.test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\":valid_data},\n",
    "            y=valid_labels,\n",
    "            num_epochs=1,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        # Input for final testing after evolution\n",
    "        self.results_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\":test_data},\n",
    "            y=test_labels,\n",
    "            num_epochs=1,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        self.pop = []\n",
    "        for i in range(pop_size):\n",
    "            new_tree = Tree('g0-'+str(i), num_nodes=1)\n",
    "            new_tree.show()\n",
    "            self.pop.append(new_tree)\n",
    "\n",
    "    def evolve(self, eras):\n",
    "        history = []\n",
    "        start = tic()\n",
    "        for e in range(eras):\n",
    "            print(\"Starting Era {}...\".format(e))\n",
    "            era_hist = []\n",
    "            ofage = 0\n",
    "            for tree in self.pop:\n",
    "                if tree.age < self.elder:\n",
    "                    try:\n",
    "                        tree.train(self.train_fn, steps=self.era_len)\n",
    "                    except:\n",
    "                        tree.show()\n",
    "                        raise ValueError(\"Tensorflow Messed Up...\")\n",
    "                if tree.age >= self.adult:\n",
    "                    ofage+=1\n",
    "                    tree.test(self.test_fn)\n",
    "                    era_hist.append(tree.fitness)\n",
    "            if ofage >= self.elites+self.deaths:\n",
    "                self.pop = sorted(self.pop, key=lambda x:x.fitness, reverse=True)\n",
    "                best = [self.pop[0], self.pop[1]]\n",
    "                count = 0\n",
    "                for i in range(len(self.pop)-1, -1, -1):\n",
    "                    if self.pop[i].age >= self.adult:\n",
    "                        self.pop[i] = best[0].crossover(best[1], 'g{}-{}'.format(e, count))\n",
    "                        self.pop[i].mutate()\n",
    "                        self.pop[i].show()\n",
    "                        count+=1\n",
    "                    if count >= self.deaths:\n",
    "                        break\n",
    "            if self.pop[0].fitness > 0:\n",
    "                print(\"Best fitness for era {}: {:.4f}\".format(e, best[0].fitness))\n",
    "            history.append(era_hist)\n",
    "        self.pop[0].test(self.results_fn)\n",
    "        print(\"Final best fitness after {} eras: {} = {:.4f}\".format(eras, self.pop[0].name, self.pop[0].fitness))\n",
    "        print(\"Total training time: {:.4f}\".format(tic()-start))\n",
    "        for i in range(len(self.pop)):\n",
    "            print(\"Tree #{}\".format(i))\n",
    "            self.pop[i].show()\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "---------------------------------------------\n",
      "g0-0\tlr:0.0209\n",
      "\tSize: 16\tActivation: LeakyReLU\tDropout: 0.17\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-1\tlr:0.0701\n",
      "\tSize: 16\tActivation: Linear\tDropout: 0.49\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-2\tlr:0.1095\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-3\tlr:0.0281\n",
      "\tSize: 1024\tActivation: LeakyReLU\tDropout: 0.26\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-4\tlr:0.0263\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.02\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-5\tlr:0.0811\n",
      "\tSize: 64\tActivation: Linear\tDropout: 0.16\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-6\tlr:0.076\n",
      "\tSize: 16\tActivation: Linear\tDropout: 0.13\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-7\tlr:0.1782\n",
      "\tSize: 128\tActivation: ReLU\tDropout: 0.39\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-8\tlr:0.033\n",
      "\tSize: 128\tActivation: ReLU\tDropout: 0.44\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g0-9\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.39\n",
      "---------------------------------------------\n",
      "Starting Era 0...\n",
      "Time to train model \"g0-0\": 3.7622\n",
      "Time to train model \"g0-1\": 3.6543\n",
      "Time to train model \"g0-2\": 13.4880\n",
      "Time to train model \"g0-3\": 13.7847\n",
      "Time to train model \"g0-4\": 13.5933\n",
      "Time to train model \"g0-5\": 4.2253\n",
      "Time to train model \"g0-6\": 3.6867\n",
      "Time to train model \"g0-7\": 4.4936\n",
      "Time to train model \"g0-8\": 4.4874\n",
      "Time to train model \"g0-9\": 8.1741\n",
      "Starting Era 1...\n",
      "Time to train model \"g0-0\": 3.6831\n",
      "Time to train model \"g0-1\": 3.5969\n",
      "Time to train model \"g0-2\": 13.6070\n",
      "Time to train model \"g0-3\": 13.7668\n",
      "Time to train model \"g0-4\": 13.4579\n",
      "Time to train model \"g0-5\": 4.2007\n",
      "Time to train model \"g0-6\": 3.6680\n",
      "Time to train model \"g0-7\": 4.4558\n",
      "Time to train model \"g0-8\": 4.4686\n",
      "Time to train model \"g0-9\": 8.1699\n",
      "Starting Era 2...\n",
      "Time to train model \"g0-0\": 3.6767\n",
      "Time to train model \"g0-1\": 3.6029\n",
      "Time to train model \"g0-2\": 13.5874\n",
      "Time to train model \"g0-3\": 13.6690\n",
      "Time to train model \"g0-4\": 13.4288\n",
      "Time to train model \"g0-5\": 4.2733\n",
      "Time to train model \"g0-6\": 3.6173\n",
      "Time to train model \"g0-7\": 4.4469\n",
      "Time to train model \"g0-8\": 4.5695\n",
      "Time to train model \"g0-9\": 8.1344\n",
      "Starting Era 3...\n",
      "Time to train model \"g0-0\": 3.6709\n",
      "Time to train model \"g0-1\": 3.6966\n",
      "Time to train model \"g0-2\": 13.4730\n",
      "Time to train model \"g0-3\": 13.6703\n",
      "Time to train model \"g0-4\": 13.7824\n",
      "Time to train model \"g0-5\": 4.2217\n",
      "Time to train model \"g0-6\": 3.9220\n",
      "Time to train model \"g0-7\": 4.4447\n",
      "Time to train model \"g0-8\": 4.5232\n",
      "Time to train model \"g0-9\": 8.1356\n",
      "---------------------------------------------\n",
      "g3-0\tlr:0.1095\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.39\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g3-1\tlr:0.1095\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.37\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g3-2\tlr:0.1095\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.39\n",
      "---------------------------------------------\n",
      "Best fitness for era 3: 0.9758\n",
      "Starting Era 4...\n",
      "Time to train model \"g0-2\": 13.5766\n",
      "Time to train model \"g0-9\": 8.2437\n",
      "Time to train model \"g0-7\": 4.5752\n",
      "Time to train model \"g0-4\": 13.4602\n",
      "Time to train model \"g0-8\": 4.4575\n",
      "Time to train model \"g0-3\": 13.7643\n",
      "Time to train model \"g0-0\": 3.6816\n",
      "Time to train model \"g3-2\": 13.5145\n",
      "Time to train model \"g3-1\": 13.6123\n",
      "Time to train model \"g3-0\": 13.5164\n",
      "---------------------------------------------\n",
      "g4-0\tlr:0.1095\n",
      "\tSize: 1024\tActivation: Tanh\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g4-1\tlr:0.1095\n",
      "\tSize: 512\tActivation: Linear\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g4-2\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "Best fitness for era 4: 0.9758\n",
      "Starting Era 5...\n",
      "Time to train model \"g0-2\": 13.5028\n",
      "Time to train model \"g0-9\": 8.1520\n",
      "Time to train model \"g0-7\": 4.5814\n",
      "Time to train model \"g0-4\": 13.4855\n",
      "Time to train model \"g4-2\": 13.6807\n",
      "Time to train model \"g4-1\": 7.6757\n",
      "Time to train model \"g4-0\": 12.9454\n",
      "Time to train model \"g3-2\": 13.5815\n",
      "Time to train model \"g3-1\": 13.5510\n",
      "Time to train model \"g3-0\": 13.5637\n",
      "---------------------------------------------\n",
      "g5-0\tlr:0.1095\n",
      "\tSize: 512\tActivation: Tanh\tDropout: 0.39\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g5-1\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g5-2\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.39\n",
      "---------------------------------------------\n",
      "Best fitness for era 5: 0.9778\n",
      "Starting Era 6...\n",
      "Time to train model \"g0-2\": 13.5859\n",
      "Time to train model \"g5-2\": 13.5941\n",
      "Time to train model \"g5-1\": 8.1383\n",
      "Time to train model \"g5-0\": 7.8872\n",
      "Time to train model \"g4-2\": 13.5327\n",
      "Time to train model \"g4-1\": 7.7542\n",
      "Time to train model \"g4-0\": 12.9079\n",
      "Time to train model \"g3-2\": 13.4605\n",
      "Time to train model \"g3-1\": 13.5214\n",
      "Time to train model \"g3-0\": 13.5852\n",
      "Best fitness for era 6: 0.9772\n",
      "Starting Era 7...\n",
      "Time to train model \"g0-2\": 13.5183\n",
      "Time to train model \"g5-2\": 13.4970\n",
      "Time to train model \"g5-1\": 8.2600\n",
      "Time to train model \"g5-0\": 7.8274\n",
      "Time to train model \"g4-2\": 13.4904\n",
      "Time to train model \"g4-1\": 7.7711\n",
      "Time to train model \"g4-0\": 12.9417\n",
      "Time to train model \"g3-2\": 13.5358\n",
      "Time to train model \"g3-1\": 13.5964\n",
      "Time to train model \"g3-0\": 13.4764\n",
      "---------------------------------------------\n",
      "g7-0\tlr:0.2977\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.39\n",
      "\tSize: 64\tActivation: Tanh\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g7-1\tlr:0.1095\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g7-2\tlr:0.1095\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.41\n",
      "---------------------------------------------\n",
      "Best fitness for era 7: 0.9766\n",
      "Starting Era 8...\n",
      "Time to train model \"g7-2\": 13.5273\n",
      "Time to train model \"g7-1\": 13.6252\n",
      "Time to train model \"g7-0\": 8.8463\n",
      "Time to train model \"g5-2\": 13.4797\n",
      "Time to train model \"g5-1\": 8.2851\n",
      "Time to train model \"g5-0\": 7.8624\n",
      "Time to train model \"g4-2\": 13.5549\n",
      "Time to train model \"g4-1\": 7.7199\n",
      "Time to train model \"g4-0\": 12.8909\n",
      "---------------------------------------------\n",
      "g8-0\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g8-1\tlr:0.0148\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g8-2\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "Best fitness for era 8: 0.9766\n",
      "Starting Era 9...\n",
      "Time to train model \"g8-2\": 13.6076\n",
      "Time to train model \"g8-1\": 13.5199\n",
      "Time to train model \"g8-0\": 13.6383\n",
      "Time to train model \"g7-2\": 13.5296\n",
      "Time to train model \"g7-1\": 13.4877\n",
      "Time to train model \"g7-0\": 8.9519\n",
      "Time to train model \"g5-2\": 13.5132\n",
      "Time to train model \"g5-1\": 8.2696\n",
      "Time to train model \"g5-0\": 7.9447\n",
      "---------------------------------------------\n",
      "g9-0\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g9-1\tlr:0.0451\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.33\n",
      "\tSize: 256\tActivation: Sigmoid\tDropout: 0.3\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g9-2\tlr:0.1095\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "Best fitness for era 9: 0.9772\n",
      "Starting Era 10...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train model \"g5-1\": 8.7325\n",
      "Time to train model \"g9-2\": 13.7945\n",
      "Time to train model \"g9-1\": 10.3617\n",
      "Time to train model \"g9-0\": 13.5642\n",
      "Time to train model \"g8-2\": 13.7596\n",
      "Time to train model \"g8-1\": 14.3586\n",
      "Time to train model \"g8-0\": 13.5583\n",
      "Time to train model \"g7-2\": 13.5519\n",
      "Time to train model \"g7-1\": 13.4854\n",
      "Time to train model \"g7-0\": 8.9538\n",
      "Best fitness for era 10: 0.9776\n",
      "Starting Era 11...\n",
      "Time to train model \"g5-1\": 8.1864\n",
      "Time to train model \"g9-2\": 13.6168\n",
      "Time to train model \"g9-1\": 10.9463\n",
      "Time to train model \"g9-0\": 13.4710\n",
      "Time to train model \"g8-2\": 13.6045\n",
      "Time to train model \"g8-1\": 13.5407\n",
      "Time to train model \"g8-0\": 13.5758\n",
      "Time to train model \"g7-2\": 13.6363\n",
      "Time to train model \"g7-1\": 13.4758\n",
      "Time to train model \"g7-0\": 8.9656\n",
      "---------------------------------------------\n",
      "g11-0\tlr:0.1095\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.41\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g11-1\tlr:0.1095\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g11-2\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.41\n",
      "---------------------------------------------\n",
      "Best fitness for era 11: 0.9766\n",
      "Starting Era 12...\n",
      "Time to train model \"g5-1\": 8.1887\n",
      "Time to train model \"g11-2\": 8.1846\n",
      "Time to train model \"g11-1\": 13.5312\n",
      "Time to train model \"g11-0\": 13.6813\n",
      "Time to train model \"g9-2\": 13.5484\n",
      "Time to train model \"g9-1\": 10.2571\n",
      "Time to train model \"g9-0\": 13.5740\n",
      "Time to train model \"g8-2\": 13.5362\n",
      "Time to train model \"g8-1\": 13.5399\n",
      "Time to train model \"g8-0\": 13.9658\n",
      "---------------------------------------------\n",
      "g12-0\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g12-1\tlr:0.1225\n",
      "\tSize: 512\tActivation: Sigmoid\tDropout: 0.37\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g12-2\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.33\n",
      "\tSize: 128\tActivation: Linear\tDropout: 0.26\n",
      "---------------------------------------------\n",
      "Best fitness for era 12: 0.9760\n",
      "Starting Era 13...\n",
      "Time to train model \"g8-0\": 14.8287\n",
      "Time to train model \"g12-2\": 10.7008\n",
      "Time to train model \"g12-1\": 8.4788\n",
      "Time to train model \"g12-0\": 8.4617\n",
      "Time to train model \"g11-2\": 8.5435\n",
      "Time to train model \"g11-1\": 13.6569\n",
      "Time to train model \"g11-0\": 13.7776\n",
      "Time to train model \"g9-2\": 13.8422\n",
      "Time to train model \"g9-1\": 10.7597\n",
      "Time to train model \"g9-0\": 14.1285\n",
      "---------------------------------------------\n",
      "g13-0\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g13-1\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.34\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g13-2\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "Best fitness for era 13: 0.9772\n",
      "Starting Era 14...\n",
      "Time to train model \"g9-0\": 14.2874\n",
      "Time to train model \"g13-2\": 13.8820\n",
      "Time to train model \"g13-1\": 13.9945\n",
      "Time to train model \"g13-0\": 13.9011\n",
      "Time to train model \"g12-2\": 9.2175\n",
      "Time to train model \"g12-1\": 8.3070\n",
      "Time to train model \"g12-0\": 8.3227\n",
      "Time to train model \"g11-2\": 8.3258\n",
      "Time to train model \"g11-1\": 14.0748\n",
      "Time to train model \"g11-0\": 14.0607\n",
      "Best fitness for era 14: 0.9764\n",
      "Starting Era 15...\n",
      "Time to train model \"g9-0\": 13.7845\n",
      "Time to train model \"g13-2\": 13.8248\n",
      "Time to train model \"g13-1\": 13.8547\n",
      "Time to train model \"g13-0\": 13.7297\n",
      "Time to train model \"g12-2\": 9.8246\n",
      "Time to train model \"g12-1\": 8.1264\n",
      "Time to train model \"g12-0\": 8.2387\n",
      "Time to train model \"g11-2\": 8.9875\n",
      "Time to train model \"g11-1\": 13.7135\n",
      "Time to train model \"g11-0\": 14.1753\n",
      "---------------------------------------------\n",
      "g15-0\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.41\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g15-1\tlr:0.0166\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.31\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g15-2\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "Best fitness for era 15: 0.9776\n",
      "Starting Era 16...\n",
      "Time to train model \"g9-0\": 13.8764\n",
      "Time to train model \"g15-2\": 8.2015\n",
      "Time to train model \"g15-1\": 13.8833\n",
      "Time to train model \"g15-0\": 8.6941\n",
      "Time to train model \"g13-2\": 14.5596\n",
      "Time to train model \"g13-1\": 14.1009\n",
      "Time to train model \"g13-0\": 13.8041\n",
      "Time to train model \"g12-2\": 9.4877\n",
      "Time to train model \"g12-1\": 8.2012\n",
      "Time to train model \"g12-0\": 8.3700\n",
      "---------------------------------------------\n",
      "g16-0\tlr:0.0451\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.29\n",
      "\tSize: 128\tActivation: Linear\tDropout: 0.26\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g16-1\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g16-2\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.33\n",
      "\tSize: 128\tActivation: Linear\tDropout: 0.26\n",
      "---------------------------------------------\n",
      "Best fitness for era 16: 0.9770\n",
      "Starting Era 17...\n",
      "Time to train model \"g9-0\": 13.5492\n",
      "Time to train model \"g16-2\": 9.3737\n",
      "Time to train model \"g16-1\": 13.7509\n",
      "Time to train model \"g16-0\": 9.6347\n",
      "Time to train model \"g15-2\": 8.4293\n",
      "Time to train model \"g15-1\": 14.1660\n",
      "Time to train model \"g15-0\": 8.3313\n",
      "Time to train model \"g13-2\": 14.1763\n",
      "Time to train model \"g13-1\": 13.8626\n",
      "Time to train model \"g13-0\": 14.4530\n",
      "---------------------------------------------\n",
      "g17-0\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "\tSize: 128\tActivation: LeakyReLU\tDropout: 0.09\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g17-1\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "\tSize: 16\tActivation: LeakyReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g17-2\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.46\n",
      "\tSize: 16\tActivation: Linear\tDropout: 0.0\n",
      "---------------------------------------------\n",
      "Best fitness for era 17: 0.9776\n",
      "Starting Era 18...\n",
      "Time to train model \"g13-0\": 14.3546\n",
      "Time to train model \"g17-2\": 14.0171\n",
      "Time to train model \"g17-1\": 14.3190\n",
      "Time to train model \"g17-0\": 16.0107\n",
      "Time to train model \"g16-2\": 9.5135\n",
      "Time to train model \"g16-1\": 13.8845\n",
      "Time to train model \"g16-0\": 9.6361\n",
      "Time to train model \"g15-2\": 8.2287\n",
      "Time to train model \"g15-1\": 13.7278\n",
      "Time to train model \"g15-0\": 8.3502\n",
      "Best fitness for era 18: 0.9776\n",
      "Starting Era 19...\n",
      "Time to train model \"g13-0\": 13.7102\n",
      "Time to train model \"g17-2\": 13.8977\n",
      "Time to train model \"g17-1\": 14.0326\n",
      "Time to train model \"g17-0\": 15.5529\n",
      "Time to train model \"g16-2\": 9.5294\n",
      "Time to train model \"g16-1\": 13.7761\n",
      "Time to train model \"g16-0\": 9.3329\n",
      "Time to train model \"g15-2\": 8.4875\n",
      "Time to train model \"g15-1\": 13.9291\n",
      "Time to train model \"g15-0\": 8.3936\n",
      "---------------------------------------------\n",
      "g19-0\tlr:0.0451\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g19-1\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "g19-2\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "Best fitness for era 19: 0.9774\n",
      "Final best fitness after 20 eras: g13-0 = 0.9910\n",
      "Total training time: 2163.6908\n",
      "Tree #0\n",
      "---------------------------------------------\n",
      "g13-0\tlr:0.1225\n",
      "\tFitness: 0.9909999966621399\tAccuracy: 0.9909999966621399\tLoss: 0.026561256498098373\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "Tree #1\n",
      "---------------------------------------------\n",
      "g19-2\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "Tree #2\n",
      "---------------------------------------------\n",
      "g19-1\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "Tree #3\n",
      "---------------------------------------------\n",
      "g19-0\tlr:0.0451\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "Tree #4\n",
      "---------------------------------------------\n",
      "g17-2\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.46\n",
      "\tSize: 16\tActivation: Linear\tDropout: 0.0\n",
      "---------------------------------------------\n",
      "Tree #5\n",
      "---------------------------------------------\n",
      "g17-1\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "\tSize: 16\tActivation: LeakyReLU\tDropout: 0.27\n",
      "---------------------------------------------\n",
      "Tree #6\n",
      "---------------------------------------------\n",
      "g17-0\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "\tSize: 128\tActivation: LeakyReLU\tDropout: 0.09\n",
      "---------------------------------------------\n",
      "Tree #7\n",
      "---------------------------------------------\n",
      "g16-2\tlr:0.1225\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.33\n",
      "\tSize: 128\tActivation: Linear\tDropout: 0.26\n",
      "---------------------------------------------\n",
      "Tree #8\n",
      "---------------------------------------------\n",
      "g16-1\tlr:0.1225\n",
      "\tSize: 1024\tActivation: ReLU\tDropout: 0.33\n",
      "---------------------------------------------\n",
      "Tree #9\n",
      "---------------------------------------------\n",
      "g16-0\tlr:0.0451\n",
      "\tSize: 512\tActivation: ReLU\tDropout: 0.29\n",
      "\tSize: 128\tActivation: Linear\tDropout: 0.26\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pool = Population()\n",
    "hist = pool.evolve(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Growth rate = 0.1, Shrink Rate = 0.1, Mutation Rate = 0.001\n",
    "\n",
    "Final best fitness after 20 eras: g13-1 0.9902\n",
    "Total training time: 1671.30\n",
    "    Tree #0\n",
    "    ---------------------------------------------\n",
    "    g13-1\tlr:0.1779\n",
    "        Fitness: 0.9901\tAccuracy: 0.9902\tLoss: 0.0593\n",
    "        Size: 512\tActivation: Tanh\tDropout: 0.01\n",
    "        Size: 32\tActivation: LeakyReLU\tDropout: 0.5\n",
    "    ---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Growth rate = 0.1, Shrink rate = 0.1, mutation rate = 0.001\n",
    "\n",
    "Best fitness for era 19: 0.9774\n",
    "Final best fitness after 20 eras: g13-0 = 0.9910\n",
    "\n",
    "Total training time: 2163.6908\n",
    "    Tree #0\n",
    "    ---------------------------------------------\n",
    "    g13-0\tlr:0.1225\n",
    "        Fitness: 0.9909999966621399\tAccuracy: 0.9909999966621399\tLoss: 0.026561256498098373\n",
    "        Size: 1024\tActivation: ReLU\tDropout: 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
